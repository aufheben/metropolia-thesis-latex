% Abstract in English
%Most probably, you only need to change the text of the abstract. Everything else comes from chapter/0info.tex
%If you do not have any appendix, you may delete \total{chapter} and replace with 0

\pagestyle{abstract}
\begin{otherlanguage}{english}
{\renewcommand{\arraystretch}{2}%
\begin{tabular}{ | p{4,7cm} | p{10,3cm} |}
  \hline
  Author(s) \newline
  Title \newline\newline 
  Number of Pages \newline
  Date
  & 
  \makeatletter
  \@author \newline
  \@title \newline\newline
  \pageref*{LastPage} pages + \total{chapter} appendices \newline %! if no appendices, risk to count total of chapter :D
  \IfLanguageName {finnish} {\foreignlanguage{english}{\longdate\@date}} {\@date}
  \makeatother
  \\ \hline
  Degree & \metropoliadegree
  \\ \hline
  Degree Programme & \metropoliadegreeprogramme
  \\ \hline
  Professional Major & \metropoliaspecialisation
  \\ \hline
  Instructor(s) & \metropoliainstructors
  \\ \hline
  \multicolumn{2}{|p{15cm}|}{\vspace{-22pt}
  The parallel nature of FPGA makes it a promising candidate to accelerate machine learning tasks. In
  this thesis we describe an implementation of a generative model on the FPGA with Verilog. The pre-trained
  model is part of the popular Generative Adversarial Networks (GANs) which can create realistic images. We
  discuss the quantization of the model from high precision floating-point representation to low precision
  integral representation. The quantization scheme leads to an efficient implementation the General Matrix
  Multiplication (GEMM) operation, which is at the heart of neural network computations. The implementation
  and optimization details specific to FPGA are also described. Finally, we briefly compare FPGA, ASIC, and
  GPU for machine learning acceleration.
  \newline

  beginning of second paragraph\ldots
  } \\[14cm] \hline
  Keywords & \metropoliakeywords
  \\ \hline
\end{tabular}
}
\end{otherlanguage}
\clearpage

