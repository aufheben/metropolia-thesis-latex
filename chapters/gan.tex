% Project Specifications

\chapter{A Description of GANs}

There are two networks in a GANs model: $D$, the discriminator, and $G$, the generator. $D$ is a regular
classifier which models a funtion $f: X -> Y$ where $X$ are the input examples and $Y = {1, 0}$ are labels
that identify the input examples as "authentic" or not. $G$, on the other hand, learns the probability
distribution that generates the input samples and corresponding labels. If the learning is successful,
$G$ will be able to create new samples from the distribution it has learned.

During the training, we feed two types of examples to $D$: existing training examples and examples generated
by $G$. The task of $D$ is to learn to correctly label both types of examples. Meanwhile, $G$ learns to
generate examples that mimic real world examples. The training process improves the ability of both $D$
and $G$, until eventually the output of $G$ will be indistinguishable from real world examples to $D$. Once
trained, $D$ can be discarded and $G$ can be used in different applications.

In the original paper they are both multilayer perceptrons, however many different network types have been
proposed since then. In this project, $D$ and $G$ are both deep convolutional neural networks which are
suitable for image processing. The training of $D$ and $G$ is done on GPU with floating-point numbers. Since
$D$ is discarded after training, from now on we are only concerned with $G$.

Below is the network structure of $G$:

$G$ consists of five transposed convolutional layers. Except for the last layer, the previous four layers
each are followed by a layer of batch normalization, and a layer of rectified linear units (ReLU) for
activation. The last transposed convolutional layer is followed by a layer of $tanh$ function applied to
each element as activation. The network structure is rather simple compared with many other much larger
networks, such as ResNet which has 152 layers.

\clearpage %force the next chapter to start on a new page. Keep that as the last line of your chapter!
